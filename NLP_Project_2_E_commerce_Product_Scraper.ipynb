{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZmFSfy/Dy05tN43cCOAO7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amanrathi087/NLP-Project-2-E-commerce-Product-Scraper/blob/main/NLP_Project_2_E_commerce_Product_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "1Od8p2iNQNpy",
        "outputId": "36be0e07-77e1-4509-ad3c-03b50a2d2dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "‚ùå No products found! Flipkart page structure may have changed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3826965357.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚ùå No products found! Flipkart page structure may have changed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Price\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coerce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ‚ùå No products found! Flipkart page structure may have changed."
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# üõí Project 2: E-Commerce Product Scraper (Flipkart)\n",
        "# ============================================================\n",
        "\n",
        "!pip install requests beautifulsoup4 pandas lxml openpyxl\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1 ‚Äì choose a search keyword\n",
        "search = \"laptop\"   # üîç change to \"mobile\", \"headphones\", etc.\n",
        "url = f\"https://www.flipkart.com/search?q={search}\"\n",
        "\n",
        "# Step 2 ‚Äì fetch the page\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"lxml\")\n",
        "\n",
        "# Step 3 ‚Äì extract product info\n",
        "products = []\n",
        "\n",
        "# üîπ this loop defines 'item', so inside it we can use item.find(...)\n",
        "for item in soup.find_all(\"div\", {\"class\": \"_1AtVbE\"})[:50]:\n",
        "    # name can appear under several class names\n",
        "    name = None\n",
        "    for cls in [\"_4rR01T\", \"IRpwTa\", \"s1Q9rs\"]:\n",
        "        tag = item.find(\"div\", {\"class\": cls}) or item.find(\"a\", {\"class\": cls})\n",
        "        if tag:\n",
        "            name = tag.text.strip()\n",
        "            break\n",
        "\n",
        "    # price\n",
        "    price_tag = item.find(\"div\", {\"class\": \"_30jeq3\"})\n",
        "    price = price_tag.text.strip(\"‚Çπ\").replace(\",\", \"\") if price_tag else None\n",
        "\n",
        "    # rating\n",
        "    rating_tag = item.find(\"div\", {\"class\": \"_3LWZlK\"})\n",
        "    rating = rating_tag.text if rating_tag else None\n",
        "\n",
        "    if name and price:\n",
        "        products.append({\n",
        "            \"Name\": name,\n",
        "            \"Price\": price,\n",
        "            \"Rating\": rating if rating else \"N/A\"\n",
        "        })\n",
        "\n",
        "# Step 4 ‚Äì make a DataFrame\n",
        "df = pd.DataFrame(products)\n",
        "if df.empty:\n",
        "    raise ValueError(\"‚ùå No products found! Flipkart page structure may have changed.\")\n",
        "\n",
        "df[\"Price\"] = pd.to_numeric(df[\"Price\"], errors=\"coerce\")\n",
        "df[\"Rating\"] = pd.to_numeric(df[\"Rating\"].replace(\"N/A\", None), errors=\"coerce\")\n",
        "\n",
        "print(f\"‚úÖ Scraped {len(df)} products successfully!\")\n",
        "display(df.head())\n",
        "\n",
        "# Step 5 ‚Äì analysis\n",
        "avg_price = df[\"Price\"].mean()\n",
        "top_product = df.loc[df[\"Rating\"].idxmax()]\n",
        "\n",
        "print(\"\\nüí∞ Average Price: ‚Çπ\", round(avg_price, 2))\n",
        "print(\"\\n‚≠ê Top-Rated Product:\")\n",
        "display(top_product.to_frame().T)\n",
        "\n",
        "# Step 6 ‚Äì save to Excel\n",
        "df.to_excel(\"flipkart_products.xlsx\", index=False)\n",
        "print(\"\\nüìÅ Saved results as flipkart_products.xlsx\")\n"
      ]
    }
  ]
}